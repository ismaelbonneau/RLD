{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dueling Double DQN\n",
    "\n",
    "_Ismaël Bonneau_\n",
    "\n",
    "\n",
    "## Modèle & architecture\n",
    "\n",
    "Comme indiqué dans le titre, ce modèle est une amélioration du **DQN**. Il reprend tous ses principes, comme le experience replay, le remplacement de la target tous les ${C}$ pas de temps, mais diffère en un point. \n",
    "\n",
    "Avec un **DQN**, notre réseau prend ${\\phi(s)}$ en entrée et sort ${Q(s,a)}$ les valeurs des actions pour cet état ${s}$. Généralement, dans le cas d'un jeu, ${\\phi(s)}$ correspond à un réseau de convolution (CNN).\n",
    "\n",
    "Avec un **DDQN**, on prend ${\\phi(s)}$ et on le traite avec 2 réseaux différents, pour produire deux sorties:\n",
    "- ${V(s)}$ qui est la \"valeur\" de l'état, ou combien il est intéressant d'être dans cet état.\n",
    "- ${A(s, a)}$ qui est la fonction avantage (rappel: <a href=\"\">actor-critic</a>) et qui indique combien il est avantageux, quand on se trouve dans l'état ${s}$, d'effectuer l'action ${a}$ par rapport aux autres actions.\n",
    "\n",
    "### Architecture du réseau de neurones:\n",
    "\n",
    "L'architecture du modèle est composée d'un premier réseau de convolution, qui va prendre en entrée les frames du jeu (généralement stackées par groupe, nous verrons ça plus tard)\n",
    "\n",
    "<img src=\"images/dueling-q-network.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous allons appliquer ce modèle sur un jeu bien connu, super Mario bros.\n",
    "\n",
    "Ce jeu n'est pas disponible dans l'environnement gym par défaut. Il doit être installé à part (avec d'autres packages comme pyNes)\n",
    "\n",
    "<img src=\"images/mario.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state = env.reset()\n",
    "state, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "print(\"frame shape: \", state.shape)\n",
    "print(\"game status: \")\n",
    "pp.pprint(info)\n",
    "plt.imshow(state)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
