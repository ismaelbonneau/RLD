{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dueling Double DQN\n",
    "\n",
    "_Ismaël Bonneau_\n",
    "\n",
    "\n",
    "## Modèle & architecture\n",
    "\n",
    "Comme indiqué dans le titre, ce modèle est une amélioration du **DQN**. Il reprend tous ses principes, comme le experience replay, le remplacement de la target tous les ${C}$ pas de temps, mais diffère en un point. \n",
    "\n",
    "Avec un **DQN**, notre réseau prend ${\\phi(s)}$ en entrée et sort ${Q(s,a)}$ les valeurs des actions pour cet état ${s}$. Généralement, dans le cas d'un jeu, ${\\phi(s)}$ correspond à un réseau de convolution (CNN).\n",
    "\n",
    "Avec un **DDQN**, on prend ${\\phi(s)}$ et on le traite avec 2 réseaux différents, pour produire deux sorties:\n",
    "- ${V(s)}$ qui est la \"valeur\" de l'état, ou combien il est intéressant d'être dans cet état.\n",
    "- ${A(s, a)}$ qui est la fonction avantage (rappel: <a href=\"\">actor-critic</a>) et qui indique combien il est avantageux, quand on se trouve dans l'état ${s}$, d'effectuer l'action ${a}$ par rapport aux autres actions.\n",
    "\n",
    "Ces deux valeurs sont ensuite combinées pour former ${Q(s,a)}$. On n'utilise pas la somme pour combiner les deux (ce qui normalement est bien la formule: ${Q(s,a) = V(s) + A(s,a)}$ mais une autre formule, ${Q(s,a) = V(s) + (A(s,a) - \\frac{1}{|A|} \\sum_{a}{A(s,a)})}$. (Dire pourquoi)\n",
    "\n",
    "### Architecture du réseau de neurones:\n",
    "\n",
    "L'architecture du modèle pour la fonction ${\\phi}$ est composée d'un réseau de convolution, qui va prendre en entrée les frames du jeu (généralement stackées par groupe, nous verrons ça plus tard). Elle calcule une représentation des frames, puis la donne à l'autre partie du modèle, qui consiste en 2 branches de fully-connected.\n",
    "\n",
    "<img src=\"images/dueling-q-network.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La première partie du réseau:\n",
    "\n",
    "Il s'agit de la fonction ${\\phi}$. Elle est composée de 3 couches de convolution.\n",
    "\n",
    "- 32 filtres + max-pooling \n",
    "- 64 filtres + max-pooling\n",
    "- 64 filtres + max-pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\" Basic ConvNet similar to LeNet \"\"\"\n",
    "    def __init__(self, input_channel):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, 32, (5,5), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2), stride=2, padding=0),\n",
    "            nn.Conv2d(32, 64, (5,5), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2), stride=2, padding=0),\n",
    "            nn.Conv2d(64, 64, (5,5), stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2), stride=2, padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.reshape(out.size(0), -1) # flatten\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La partie dueling:\n",
    "\n",
    "Deux branches, deux fully-connected: une pour calculer ${A(s,a)}$, une pour le calcul de ${V(s)}$. \n",
    "\n",
    "Il combine les deux ensuite en calculant ${Q(s,a) = V(s) + (A(s,a) - \\frac{1}{|A|} \\sum_{a}{A(s,a)})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, action_space_size):\n",
    "        super(DuelingNet, self).__init__()\n",
    "        # here we branch the network: one branch for V(s), another for A(s,a)\n",
    "        self.V_nn = nn.Sequential(nn.Linear(input_dim, 1), nn.Tanh())\n",
    "        self.advantage_nn = nn.Sequential(nn.Linear(input_dim, action_space_size), nn.Tanh())\n",
    "        \n",
    "    def forward(self, phi_s):\n",
    "        # compute V(phi(s)) and A(phi(s))\n",
    "        v = self.V_nn(phi_s)\n",
    "        advantage = self.advantage_nn(phi_s)\n",
    "        \n",
    "        # combine the two according to the formula:\n",
    "        out = v + (advantage - advantage.mean())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, action_space_size):\n",
    "        super(DDQNNet, self).__init__()\n",
    "        self.phi = ConvNet(input_dim)\n",
    "        self.duel = DuelingNet(4094, action_space_size)\n",
    "    def forward(self, x):\n",
    "        return self.duel(self.phi(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut maintenant coder le DDQN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQN(object):\n",
    "    def __init__(self, N_STATES, N_ACTIONS, MEMORY_CAPACITY, \n",
    "                 NN_layers = [32], \n",
    "                 LR = 0.01, \n",
    "                 EPSILON = 0.1,\n",
    "                 BATCH_SIZE = 32,\n",
    "                 TARGET_REPLACE_ITER = 100,\n",
    "                 GAMMA = 0.9):\n",
    "        \n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.TARGET_REPLACE_ITER = TARGET_REPLACE_ITER\n",
    "        self.EPSILON = EPSILON\n",
    "        self.LR = LR\n",
    "        self.N_ACTIONS = N_ACTIONS\n",
    "        self.N_STATES = N_STATES\n",
    "        self.MEMORY_CAPACITY = MEMORY_CAPACITY\n",
    "        self.GAMMA = GAMMA\n",
    "        \n",
    "        self.eval_net = DDQNNet(N_STATES, N_ACTIONS)\n",
    "        self.target_net = DDQNNet(N_STATES, N_ACTIONS)\n",
    "\n",
    "        self.learn_step_counter = 0                                     # for target updating\n",
    "        self.memory_counter = 0                                         # for storing memory\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))     # initialize memory\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n",
    "        self.loss_func = nn.SmoothL1Loss()\n",
    "    \n",
    "        self.transformations = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Lambda(lambda x: transforms.functional.crop(x, 40, 30, 200, 200)), # retourne image recadrée\n",
    "            transforms.Resize(64),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def preprocess(self, x):\n",
    "        return self.transformations(x)\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        if np.random.uniform() > self.EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].item()\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, self.N_ACTIONS)\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        transition = np.hstack((self.preprocess(s), [a, r], self.preprocess(s_)))\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % self.MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % self.TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        sample_index = np.random.choice(self.MEMORY_CAPACITY, self.BATCH_SIZE)\n",
    "        b_memory = self.memory[sample_index, :]\n",
    "        b_s = torch.FloatTensor(b_memory[:, :self.N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:, self.N_STATES:self.N_STATES+1].astype(int))\n",
    "        b_r = torch.FloatTensor(b_memory[:, self.N_STATES+1:self.N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -self.N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        q_next = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + self.GAMMA * q_next.max(1)[0].view(self.BATCH_SIZE, 1)   # shape (batch, 1)\n",
    "        loss = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous allons appliquer ce modèle sur un jeu bien connu, super Mario bros.\n",
    "\n",
    "Ce jeu n'est pas disponible dans l'environnement gym par défaut. Il doit être installé à part (avec d'autres packages comme pyNes)\n",
    "\n",
    "<img src=\"images/mario.gif\" width=\"400\">\n",
    "\n",
    "Commençons par configurer notre environnement super mario bros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les mouvements que peut faire mario, dans notre configuration:\n",
    "\n",
    "Pour ceux qui n'y ont jamais joué, A est la touche de saut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left']]\n"
     ]
    }
   ],
   "source": [
    "print(SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode _step_ de l'environnement nous renvoie le nouvel état, la récompense, un booléen indiquant si le jeu est fini et le dictionnaire _info_ qui contient des informations sur la partie: combien de pièces récoltées, combien de vies, le score, etc. L'état prend la forme d'une image, la frame du jeu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame shape:  (240, 256, 3)\n",
      "game status: \n",
      "{   'coins': 0,\n",
      "    'flag_get': False,\n",
      "    'life': 2,\n",
      "    'score': 0,\n",
      "    'stage': 1,\n",
      "    'status': 'small',\n",
      "    'time': 400,\n",
      "    'world': 1,\n",
      "    'x_pos': 40,\n",
      "    'x_pos_screen': 40,\n",
      "    'y_pos': 79}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "state, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "print(\"frame shape: \", state.shape)\n",
    "print(\"game status: \")\n",
    "pp.pprint(info)\n",
    "plt.imshow(state)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commençons tous les pré-traitements préalables\n",
    "\n",
    "Il faut commencer par traiter les frames. Comme on l'a vu, un état du jeu correspond à une frame de dimension ${(240, 256, 3)}$ (3 car en couleur). Il faut pré-traiter ces images pour les donner en entrée à un petit réseau de convolution ${\\phi}$ qui produira ${\\phi(s)}$\n",
    "\n",
    "\n",
    "#### Quels sont les pré traitements que l'on peut réaliser?:\n",
    "\n",
    "- On peut mettre en évidence artificiellement mario?\n",
    "- Recadrage: on va \"crop\" l'image (on peut se débarasser du haut du ciel par exemple, avec le score et les vies) et redimensionner l'image qui est trop grande.\n",
    "- Redimensionnement: passer d'une image ${240 \\times256}$ à une image ${64 \\times64}$ ne serait pas un luxe: cela diminuera le nombre de paramètres de notre CNN ${Q}$ et accélèrera l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Lambda(lambda x: transforms.functional.crop(x, 40, 30, 200, 200)), # retourne image recadrée\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transformations(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.axis('off')\n",
    "ax1.title.set_text(\"image avant prétraitements\")\n",
    "ax1.imshow(state)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.axis('off')\n",
    "ax2.title.set_text(\"image après prétraitements\")\n",
    "ax2.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "some of the strides of a given numpy array are negative. This is currently not supported, but will be added in future releases.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-2c89ae0ce561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mobs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#s_, r, done, info = env.step(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-4ac1a598000b>\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;31m# input only one sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPSILON\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# greedy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: some of the strides of a given numpy array are negative. This is currently not supported, but will be added in future releases."
     ]
    }
   ],
   "source": [
    "MEMORY_CAPACITY = 2000\n",
    "N_ACTIONS = env.action_space.n\n",
    "N_STATES = env.observation_space.shape[0]\n",
    "TARGET_REPLACE_ITER = 200\n",
    "GAMMA = 0.9\n",
    "# Enregistrement de l'Agent\n",
    "ddqn = DDQN(3, N_ACTIONS, MEMORY_CAPACITY)\n",
    "\n",
    "episode_count = 1000000\n",
    "reward = 0\n",
    "done = False\n",
    "env.verbose = True\n",
    "env.seed(0)\n",
    "np.random.seed(42)\n",
    "rsum = 0\n",
    "\n",
    "for i in range(episode_count):\n",
    "    obs = env.reset()\n",
    "    env.verbose = (i % 100 == 0 and i > 0)  # afficher 1 episode sur 100\n",
    "    if env.verbose:\n",
    "        env.render()\n",
    "    j = 0\n",
    "    rsum = 0\n",
    "    while True:\n",
    "        action = ddqn.choose_action(obs)\n",
    "        obs_, reward, done, _ = env.step(action)\n",
    "        #s_, r, done, info = env.step(a)\n",
    "        r = reward\n",
    "        ddqn.store_transition(obs, action, r, obs_)\n",
    "        rsum += r\n",
    "        j += 1\n",
    "            \n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "            ddqn.learn()\n",
    "                \n",
    "        obs = obs_\n",
    "        if env.verbose:\n",
    "            env.render()\n",
    "        if done:\n",
    "            print(\"Episode : \" + str(i) + \" rsum=\" + str(rsum) + \", \" + str(j) + \" actions\")\n",
    "            break\n",
    "\n",
    "print(\"done\")\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
